{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-predictions",
   "metadata": {},
   "source": [
    "# Notebook 4 – Predictions and visualization\n",
    "\n",
    "Purpose:\n",
    "- Load the latest trained model.\n",
    "- Fetch weather forecast for at least the next day and build future features.\n",
    "- Generate price predictions for the forecast horizon.\n",
    "- Optionally write predictions to a `electricity_prices_predictions` feature group.\n",
    "- Produce plots (hourly price forecast, forecast vs actual) and save them under `plots/` for the dashboard.\n",
    "\n",
    "Notes:\n",
    "- Document where plots are stored and naming conventions.\n",
    "- Mention any steps needed when the model version changes.\n",
    "- Indicate how often this notebook is expected to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a4b50b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:00:39.816762Z",
     "start_time": "2025-12-22T20:00:38.466607Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import warnings\n",
    "import holidays\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "\n",
    "# 1. Find project root (one level up from notebooks/)\n",
    "root_dir = Path(\"..\").resolve()\n",
    "\n",
    "# 2. Add project root to PYTHONPATH so we can import the src package\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# 3. Load .env from project root\n",
    "env_path = root_dir / \".env\"\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# 4. Load settings and utility functions (after adjusting PYTHONPATH)\n",
    "from src.config import ElectricitySettings\n",
    "from src import util\n",
    "\n",
    "settings = ElectricitySettings()\n",
    "\n",
    "# 5. Log in to Hopsworks and get feature store\n",
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "\n",
    "print(\"Successfully logged in to Hopsworks project:\", settings.HOPSWORKS_PROJECT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectricitySettings initialized\n",
      "2025-12-22 21:00:38,474 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-12-22 21:00:38,475 INFO: Initializing external client\n",
      "2025-12-22 21:00:38,476 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-22 21:00:39,318 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/127\n",
      "Successfully logged in to Hopsworks project: ScalableProject\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "2d9f9daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:00:45.354278Z",
     "start_time": "2025-12-22T20:00:45.352235Z"
    }
   },
   "source": [
    "today = datetime.datetime.now() - datetime.timedelta(0)\n",
    "yesterday = today - datetime.timedelta(days = 1)\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "60665405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:00:46.471977Z",
     "start_time": "2025-12-22T20:00:46.370864Z"
    }
   },
   "source": [
    "secrets = hopsworks.get_secrets_api()\n",
    "area = secrets.get_secret(\"ELECTRICITY_LOCATION_JSON\").value\n",
    "area = json.loads(area)\n",
    "PRICE_AREA = area['price_area']\n",
    "CITY = area['city']\n",
    "LATITUDE = area['latitude']\n",
    "LONGITUDE = area['longitude']"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "4dda89cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:00:52.287237Z",
     "start_time": "2025-12-22T20:00:47.660355Z"
    }
   },
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "# Load exact per-sensor model for this slug (no fallback)\n",
    "model_name = f\"electricity_prices_xgboost_model_lags_{PRICE_AREA.lower()}\"\n",
    "retrieved_model = mr.get_model(name=model_name)\n",
    "if retrieved_model is None:\n",
    "    raise RuntimeError(f\"Model '{model_name}' not found in registry\")\n",
    "\n",
    "# Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/5335463 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58bab3d342a24fa6a8493cddfe9df222"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/115919 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ae8a89c1fee4d56bcd3f329fc4bb531"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/115919 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ff4bfbc466e41a5a6fea3919e3e7331"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 3 files)... DONE\r"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "e99bd510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:03:21.273017Z",
     "start_time": "2025-12-22T20:03:21.199150Z"
    }
   },
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# retrieved_xgboost_model = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "retrieved_xgboost_model = XGBRegressor()\n",
    "\n",
    "retrieved_xgboost_model.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "retrieved_xgboost_model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score='6.099053E-1', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['int', 'int', 'float', 'float', 'float', 'float',\n",
       "                            'float', 'float', 'float', 'float', 'float',\n",
       "                            'float', 'float', 'float', 'int', 'in...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;6.099053E-1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;int&#x27;, &#x27;int&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;, &#x27;in...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;6.099053E-1&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;int&#x27;, &#x27;int&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;, &#x27;in...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "b1d3c92c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T20:03:33.646840Z",
     "start_time": "2025-12-22T20:03:31.450660Z"
    }
   },
   "source": [
    "# --- Fetch historical prices (last 4 days) to build lag features ---\n",
    "electricity_prices_fg = fs.get_feature_group('electricity_prices', version=1)\n",
    "lookback_start = (pd.Timestamp.utcnow() - pd.Timedelta(days=4)).normalize()\n",
    "\n",
    "hist_prices = electricity_prices_fg.filter(\n",
    "    (electricity_prices_fg.price_area == PRICE_AREA.lower()) &\n",
    "    (electricity_prices_fg.date >= lookback_start)\n",
    ").read()\n",
    "\n",
    "hist_prices['date'] = pd.to_datetime(hist_prices['date'], utc=True)\n",
    "hist_prices = hist_prices.sort_values('unix_time')[['price_area','date','hour','unix_time','price_sek']]\n",
    "\n",
    "# --- Fetch weather forecast for kommande dagar ---\n",
    "forecast_days = 2  \n",
    "forecast_df = util.get_hourly_weather_forecast(\n",
    "    latitude=LATITUDE,\n",
    "    longitude=LONGITUDE,\n",
    "    city=PRICE_AREA.lower(),\n",
    "    forecast_days=forecast_days,\n",
    ")\n",
    "forecast_df['date'] = pd.to_datetime(forecast_df['timestamp'], utc=True)\n",
    "forecast_df['unix_time'] = forecast_df['date'].astype('int64') // 10**6\n",
    "forecast_df['price_area'] = PRICE_AREA.lower()\n",
    "forecast_df['price_area'] = forecast_df['price_area'].astype('string')\n",
    "if 'city' in forecast_df.columns:\n",
    "    forecast_df = forecast_df.drop(columns=['city'])\n",
    "forecast_df = forecast_df.drop(columns=['timestamp'])\n",
    "\n",
    "# Behåll bara imorgon\n",
    "forecast_day = (pd.Timestamp.utcnow().normalize() + pd.Timedelta(days=1)).date()\n",
    "forecast_df = forecast_df[forecast_df['date'].dt.date == forecast_day].copy()\n",
    "\n",
    "# Kalender/helg/season/holiday\n",
    "forecast_df['weekday'] = forecast_df['date'].dt.weekday.astype('int8')\n",
    "forecast_df['is_weekend'] = forecast_df['weekday'].isin([5, 6]).astype('int8')\n",
    "forecast_df['month'] = forecast_df['date'].dt.month.astype('int8')\n",
    "season_map = {12: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3}\n",
    "forecast_df['season'] = forecast_df['month'].map(season_map).astype('int8')\n",
    "try:\n",
    "    years = range(forecast_df['date'].dt.year.min(), forecast_df['date'].dt.year.max() + 1)\n",
    "    se_holidays = holidays.Sweden(years=years)\n",
    "    forecast_df['is_holiday'] = forecast_df['date'].dt.date.isin(se_holidays).astype('int8')\n",
    "except Exception:\n",
    "    forecast_df['is_holiday'] = 0\n",
    "\n",
    "# --- Bygg lag features genom att kombinera historik + forecast-platshållare ---\n",
    "forecast_prices = forecast_df[['price_area','date','hour','unix_time']].copy()\n",
    "forecast_prices['price_sek'] = np.nan\n",
    "\n",
    "lag_base = pd.concat([\n",
    "    hist_prices[['price_area','date','hour','unix_time','price_sek']],\n",
    "    forecast_prices\n",
    "], ignore_index=True).sort_values('unix_time')\n",
    "\n",
    "for lag in [24, 48, 72]:\n",
    "    lag_base[f'price_lag_{lag}'] = lag_base.groupby('price_area')['price_sek'].shift(lag).astype('float32')\n",
    "\n",
    "lag_base['price_roll3d'] = (\n",
    "    lag_base.groupby('price_area')['price_sek']\n",
    "            .rolling(72, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "            .astype('float32')\n",
    ")\n",
    "\n",
    "# Plocka ut lag-features för forecast-rader\n",
    "lags_forecast = lag_base[lag_base['price_sek'].isna()][['unix_time','price_lag_24','price_lag_48','price_lag_72','price_roll3d']]\n",
    "forecast_df = forecast_df.merge(lags_forecast, on='unix_time', how='left')\n",
    "\n",
    "# --- Förbered feature-matris för inferens ---\n",
    "# Matcha träningsnamn: price-features är prefixade av Hopsworks (electricity_prices_*)\n",
    "forecast_df = forecast_df.copy()\n",
    "forecast_df['electricity_prices_unix_time'] = forecast_df['unix_time']\n",
    "forecast_df['electricity_prices_weekday'] = forecast_df['weekday']\n",
    "forecast_df['electricity_prices_is_weekend'] = forecast_df['is_weekend']\n",
    "forecast_df['electricity_prices_month'] = forecast_df['month']\n",
    "forecast_df['electricity_prices_season'] = forecast_df['season']\n",
    "forecast_df['electricity_prices_is_holiday'] = forecast_df['is_holiday']\n",
    "forecast_df['electricity_prices_price_lag_24'] = forecast_df['price_lag_24']\n",
    "forecast_df['electricity_prices_price_lag_48'] = forecast_df['price_lag_48']\n",
    "forecast_df['electricity_prices_price_lag_72'] = forecast_df['price_lag_72']\n",
    "forecast_df['electricity_prices_price_roll3d'] = forecast_df['price_roll3d']\n",
    "\n",
    "feature_cols = [\n",
    "    \"price_area\",\n",
    "    \"unix_time\",\n",
    "    \"date\",\n",
    "    \"hour\",\n",
    "    \"temperature_2m\", \"apparent_temperature\",\n",
    "    \"precipitation\", \"rain\", \"snowfall\",\n",
    "    \"cloud_cover\",\n",
    "    \"wind_speed_10m\", \"wind_speed_100m\",\n",
    "    \"wind_direction_10m\", \"wind_direction_100m\",\n",
    "    \"wind_gusts_10m\",\n",
    "    \"surface_pressure\",\n",
    "    # prefixed price cols expected by model\n",
    "    \"electricity_prices_unix_time\",\n",
    "    \"electricity_prices_weekday\",\n",
    "    \"electricity_prices_is_weekend\",\n",
    "    \"electricity_prices_month\",\n",
    "    \"electricity_prices_season\",\n",
    "    \"electricity_prices_is_holiday\",\n",
    "    \"electricity_prices_price_lag_24\",\n",
    "    \"electricity_prices_price_lag_48\",\n",
    "    \"electricity_prices_price_lag_72\",\n",
    "    \"electricity_prices_price_roll3d\",\n",
    "]\n",
    "forecast_df = forecast_df[feature_cols]\n",
    "\n",
    "cat_cols = [c for c in forecast_df.columns if 'price_area' in c]\n",
    "X_pred = forecast_df.drop(columns=['date'] + cat_cols)\n",
    "\n",
    "# --- Prediktera ---\n",
    "predictions = retrieved_xgboost_model.predict(X_pred)\n",
    "forecast_df['predicted_price_sek'] = predictions.astype('float32')\n",
    "\n",
    "# Visa resultat för imorgon\n",
    "print(forecast_df[['date','hour','predicted_price_sek']].sort_values(['date','hour']).head(24))\n"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Reading data with Hive is not supported when using hopsworks client version >= 4.0",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      2\u001B[39m electricity_prices_fg = fs.get_feature_group(\u001B[33m'\u001B[39m\u001B[33melectricity_prices\u001B[39m\u001B[33m'\u001B[39m, version=\u001B[32m1\u001B[39m)\n\u001B[32m      3\u001B[39m lookback_start = (pd.Timestamp.utcnow() - pd.Timedelta(days=\u001B[32m4\u001B[39m)).normalize()\n\u001B[32m      5\u001B[39m hist_prices = \u001B[43melectricity_prices_fg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43melectricity_prices_fg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprice_area\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mPRICE_AREA\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m&\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43melectricity_prices_fg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdate\u001B[49m\u001B[43m \u001B[49m\u001B[43m>\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookback_start\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m hist_prices[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(hist_prices[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m], utc=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     11\u001B[39m hist_prices = hist_prices.sort_values(\u001B[33m'\u001B[39m\u001B[33munix_time\u001B[39m\u001B[33m'\u001B[39m)[[\u001B[33m'\u001B[39m\u001B[33mprice_area\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mhour\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33munix_time\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33mprice_sek\u001B[39m\u001B[33m'\u001B[39m]]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/miniconda3/envs/ml-lab-py311/lib/python3.11/site-packages/hsfs/constructor/query.py:309\u001B[39m, in \u001B[36mQuery.read\u001B[39m\u001B[34m(self, online, dataframe_type, read_options)\u001B[39m\n\u001B[32m    304\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.joins) > \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [f.type \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m schema]:\n\u001B[32m    305\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    306\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mPandas types casting only supported for feature_group.read()/query.select_all()\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    307\u001B[39m         )\n\u001B[32m--> \u001B[39m\u001B[32m309\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mengine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m    \u001B[49m\u001B[43msql_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_feature_store_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43monline_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataframe_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mread_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/miniconda3/envs/ml-lab-py311/lib/python3.11/site-packages/hsfs/engine/python.py:146\u001B[39m, in \u001B[36mEngine.sql\u001B[39m\u001B[34m(self, sql_query, feature_store, online_conn, dataframe_type, read_options, schema)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msql\u001B[39m(\n\u001B[32m    137\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    138\u001B[39m     sql_query: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    143\u001B[39m     schema: Optional[List[feature.Feature]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    144\u001B[39m ) -> Union[pd.DataFrame, pl.DataFrame]:\n\u001B[32m    145\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m online_conn:\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sql_offline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[43m            \u001B[49m\u001B[43msql_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdataframe_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[43m            \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m            \u001B[49m\u001B[43marrow_flight_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43marrow_flight_config\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mread_options\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    154\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    155\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jdbc(\n\u001B[32m    156\u001B[39m             sql_query, online_conn, dataframe_type, read_options, schema\n\u001B[32m    157\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/miniconda3/envs/ml-lab-py311/lib/python3.11/site-packages/hsfs/engine/python.py:197\u001B[39m, in \u001B[36mEngine._sql_offline\u001B[39m\u001B[34m(self, sql_query, dataframe_type, schema, arrow_flight_config)\u001B[39m\n\u001B[32m    189\u001B[39m     result_df = util.run_with_loading_animation(\n\u001B[32m    190\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mReading data from Hopsworks, using Hopsworks Feature Query Service\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    191\u001B[39m         arrow_flight_client.get_instance().read_query,\n\u001B[32m   (...)\u001B[39m\u001B[32m    194\u001B[39m         dataframe_type,\n\u001B[32m    195\u001B[39m     )\n\u001B[32m    196\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    198\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mReading data with Hive is not supported when using hopsworks client version >= 4.0\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    199\u001B[39m     )\n\u001B[32m    200\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m schema:\n\u001B[32m    201\u001B[39m     result_df = Engine.cast_columns(result_df, schema)\n",
      "\u001B[31mValueError\u001B[39m: Reading data with Hive is not supported when using hopsworks client version >= 4.0"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- INSTÄLLNINGAR ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Sökvägar\n",
    "current_folder = os.getcwd()\n",
    "project_root = os.path.dirname(current_folder)\n",
    "if os.path.basename(current_folder) != \"NotebooksElectricity\":\n",
    "    project_root = current_folder\n",
    "img_path = os.path.join(project_root, \"docs/PricesDashboard/assets/img\")\n",
    "os.makedirs(img_path, exist_ok=True)\n",
    "\n",
    "# Hitta kolumnnamn för prediction i forecast_df\n",
    "price_col = 'predicted_price_sek'\n",
    "if 'prediction' in forecast_df.columns: price_col = 'prediction'\n",
    "\n",
    "print(f\"Genererar grafer till: {img_path}\")\n"
   ],
   "id": "ed3391bc28b2c47a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# GRAF 1: LADDA-GUIDEN\n",
    "# ==========================================\n",
    "mean_price = forecast_df[price_col].mean()\n",
    "forecast_df['color'] = forecast_df[price_col].apply(lambda x: '#22c55e' if x < mean_price else '#ef4444')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(forecast_df['date'], forecast_df[price_col], color=forecast_df['color'], alpha=0.9, width=0.04)\n",
    "plt.axhline(y=mean_price, color='gray', linestyle='--', alpha=0.5, label=f'Snittpris ({mean_price:.2f} kr)')\n",
    "\n",
    "plt.title('Ladda Smart Imorgon: Grönt = Billigt', fontsize=18, pad=20)\n",
    "plt.xlabel('Klockslag', fontsize=14)\n",
    "plt.ylabel('Pris (SEK/kWh)', fontsize=14)\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(img_path, \"electricity_price_signal.png\"), dpi=150)\n",
    "plt.close()\n"
   ],
   "id": "cc174256578879e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# GRAF 2: FEATURE IMPORTANCE\n",
    "# ==========================================\n",
    "try:\n",
    "    bst = retrieved_xgboost_model.get_booster()\n",
    "    importance = bst.get_score(importance_type='weight')\n",
    "\n",
    "    if not importance:\n",
    "         importance = dict(zip(X_pred.columns, retrieved_xgboost_model.feature_importances_))\n",
    "\n",
    "    imp_df = pd.DataFrame(list(importance.items()), columns=['Feature', 'Score'])\n",
    "    imp_df['Feature'] = imp_df['Feature'].str.replace('electricity_prices_', '').str.replace('weather_', '')\n",
    "    imp_df = imp_df.sort_values(by='Score', ascending=False).head(12)\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.barplot(x='Score', y='Feature', data=imp_df, palette='viridis')\n",
    "    plt.title('Vad styr elpriset just nu?', fontsize=18, pad=20)\n",
    "    plt.xlabel('Påverkan (Vikt)', fontsize=14)\n",
    "    plt.ylabel('', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(img_path, \"feature_importance.png\"), dpi=150)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Feature importance error: {e}\")\n"
   ],
   "id": "8346850ad816301b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# GRAF 3: TREND (Historisk prediktion + Framtid)\n",
    "# ==========================================\n",
    "print(\"Genererar trend-graf...\")\n",
    "\n",
    "# 1. Vi har redan 'hist_prices' (Dina faktiska priser)\n",
    "#    Men vi behöver HISTORISKT VÄDER för att modellen ska kunna gissa bakåt i tiden.\n",
    "weather_fg = fs.get_feature_group('weather_hourly', version=1)\n",
    "\n",
    "# Hämta väder för samma period som hist_prices\n",
    "# (Använd online=True för att det ska gå snabbt och funka utan Hive)\n",
    "hist_start = hist_prices['date'].min()\n",
    "hist_weather = weather_fg.filter(weather_fg.date >= hist_start).read(online=True)\n",
    "\n",
    "# Städa hist_weather\n",
    "hist_weather['date'] = pd.to_datetime(hist_weather['date'], utc=True)\n",
    "hist_weather['unix_time'] = hist_weather['date'].astype('int64') // 10**6\n",
    "hist_weather = hist_weather.sort_values('unix_time').drop_duplicates(subset=['unix_time'])\n",
    "\n",
    "# 2. Koppla ihop historiska priser med historiskt väder\n",
    "#    Detta skapar 'past_df' som modellen kan räkna på\n",
    "past_df = hist_prices.merge(hist_weather, on='unix_time', how='inner', suffixes=('', '_y'))\n",
    "past_df = past_df.loc[:, ~past_df.columns.str.endswith('_y')] # Rensa dubbletter\n",
    "\n",
    "# Lägg till Feature Engineering på historian (Samma som du gjorde för forecast)\n",
    "past_df['weekday'] = past_df['date'].dt.weekday.astype('int8')\n",
    "past_df['is_weekend'] = past_df['weekday'].isin([5, 6]).astype('int8')\n",
    "past_df['month'] = past_df['date'].dt.month.astype('int8')\n",
    "past_df['season'] = past_df['month'].map(season_map).astype('int8')\n",
    "past_df['is_holiday'] = 0 # Förenkling\n",
    "\n",
    "# Fixa lags för historian (Vi har ju faktiska priser, så vi kan räkna ut lags exakt)\n",
    "past_df['price_lag_24'] = past_df['price_sek'].shift(24)\n",
    "past_df['price_lag_48'] = past_df['price_sek'].shift(48)\n",
    "past_df['price_lag_72'] = past_df['price_sek'].shift(72)\n",
    "# Rullande medelvärde\n",
    "past_df['price_roll3d'] = past_df['price_sek'].rolling(72, min_periods=1).mean()\n",
    "\n",
    "# 3. Slå ihop DÅTID (past_df) och FRAMTID (forecast_df)\n",
    "#    forecast_df har du redan fixat features för i din kod ovan!\n",
    "full_df = pd.concat([past_df, forecast_df], ignore_index=True).sort_values('unix_time')\n",
    "\n",
    "# Fyll i eventuella hål (fill na) som uppstod vid skarven\n",
    "full_df = full_df.ffill().bfill()\n",
    "\n",
    "# 4. Mappa om kolumnnamn till det modellen vill ha (prefixet 'electricity_prices_')\n",
    "full_df['electricity_prices_unix_time'] = full_df['unix_time']\n",
    "full_df['electricity_prices_weekday'] = full_df['weekday']\n",
    "full_df['electricity_prices_is_weekend'] = full_df['is_weekend']\n",
    "full_df['electricity_prices_month'] = full_df['month']\n",
    "full_df['electricity_prices_season'] = full_df['season']\n",
    "full_df['electricity_prices_is_holiday'] = full_df['is_holiday']\n",
    "full_df['electricity_prices_price_lag_24'] = full_df['price_lag_24']\n",
    "full_df['electricity_prices_price_lag_48'] = full_df['price_lag_48']\n",
    "full_df['electricity_prices_price_lag_72'] = full_df['price_lag_72']\n",
    "full_df['electricity_prices_price_roll3d'] = full_df['price_roll3d']\n",
    "\n",
    "# 5. PREDIKTERA PÅ ALLT (Hela linjen)\n",
    "# Filtrera ut rätt features\n",
    "X_all = full_df[feature_cols].copy() # feature_cols definierade du i din kod\n",
    "# Ta bort datum/strängar\n",
    "cat_cols = [c for c in X_all.columns if 'price_area' in c]\n",
    "X_all = X_all.drop(columns=['date', 'hour'] + cat_cols, errors='ignore')\n",
    "\n",
    "# Kör modellen!\n",
    "full_df['predicted_price'] = retrieved_xgboost_model.predict(X_all)\n",
    "\n",
    "# 6. RITA GRAFEN\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Fixa datumformat för plotting\n",
    "full_df['date'] = pd.to_datetime(full_df['date'])\n",
    "hist_prices['date'] = pd.to_datetime(hist_prices['date'])\n",
    "\n",
    "# A. Orange linje (Modellens gissning för BÅDE dåtid och framtid)\n",
    "sns.lineplot(\n",
    "    x='date',\n",
    "    y='predicted_price',\n",
    "    data=full_df,\n",
    "    label='Modellens Prognos',\n",
    "    color='#f97316',\n",
    "    linewidth=2,\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "# B. Svart linje (Faktiskt utfall - Historik)\n",
    "sns.lineplot(\n",
    "    x='date',\n",
    "    y='price_sek',\n",
    "    data=hist_prices,\n",
    "    label='Faktiskt Pris',\n",
    "    color='#1e293b',\n",
    "    linewidth=3,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Markera \"NU\"\n",
    "now_time = pd.Timestamp.utcnow()\n",
    "plt.axvline(x=now_time, color='gray', linestyle=':', alpha=0.8)\n",
    "plt.text(now_time, full_df['predicted_price'].max(), ' NU ', color='gray', ha='center', backgroundcolor='white')\n",
    "\n",
    "plt.title('Pristrend: Modell vs Verklighet', fontsize=18)\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Pris (SEK)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Spara\n",
    "save_path = os.path.join(img_path, \"price_trend.png\")\n",
    "plt.savefig(save_path, dpi=150)\n",
    "print(f\"✅ Graf sparad: {save_path}\")\n",
    "plt.show()"
   ],
   "id": "4d63859be495fe9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
